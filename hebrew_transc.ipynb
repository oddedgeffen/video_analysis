{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc48bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from faster_whisper import WhisperModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f097fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = r\"C:\\video_analysis\\code\\video_analysis_saas\\media\\uploads\\audio.wav\"\n",
    "use_vad = True  # Enable VAD by default now that we have onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256b135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "compute_type = \"float32\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f14e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WhisperModel(\n",
    "    \"base\",\n",
    "    device=device,          # Use detected device (GPU or CPU)\n",
    "    compute_type=compute_type,\n",
    "    cpu_threads=4,         # Limit CPU threads\n",
    "    num_workers=1          # Reduce worker threads\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7267568",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments, info = model.transcribe(\n",
    "    audio_path,\n",
    "    language=\"he\",\n",
    "    beam_size=10,           # Conservative beam size\n",
    "    vad_filter=use_vad,       # Use VAD to skip silence\n",
    "    initial_prompt=None,   # No prompt needed\n",
    "    word_timestamps=True  # Disable word timestamps to save memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42578c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for segment in segments:\n",
    "   print(segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e97ad1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c0abe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\video_analysis\\code\\video_analysis_saas\\venv\\Lib\\site-packages\\ctranslate2\\__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "c:\\video_analysis\\code\\video_analysis_saas\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dfa4919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_path = r\"C:\\video_analysis\\code\\video_analysis_saas\\media\\uploads\\audio.wav\"\n",
    "import os\n",
    "os.path.exists(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40b2250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Run on GPU with FP16\n",
    "model = WhisperModel(\"base\", device=\"cuda\", compute_type=\"float32\")\n",
    "\n",
    "# or run on GPU with INT8\n",
    "# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n",
    "# or run on CPU with INT8\n",
    "# model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6988bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments, info = model.transcribe(p, language=\"he\", beam_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ff88384",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=r\"C:\\Users\\User\\OneDrive\\Documents\\Sound Recordings\\Recording (2).m4a\"\n",
    "segments, info = model.transcribe(p, language=\"he\", beam_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee603e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TranscriptionInfo(language='he', language_probability=1, duration=8.1493125, duration_after_vad=8.1493125, all_language_probs=None, transcription_options=TranscriptionOptions(beam_size=5, best_of=5, patience=1, length_penalty=1, repetition_penalty=1, no_repeat_ngram_size=0, log_prob_threshold=-1.0, no_speech_threshold=0.6, compression_ratio_threshold=2.4, condition_on_previous_text=True, prompt_reset_on_temperature=0.5, temperatures=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0], initial_prompt=None, prefix=None, suppress_blank=True, suppress_tokens=(1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361), without_timestamps=False, max_initial_timestamp=1.0, word_timestamps=False, prepend_punctuations='\"\\'“¿([{-', append_punctuations='\"\\'.。,，!！?？:：”)]}、', multilingual=False, max_new_tokens=None, clip_timestamps='0', hallucination_silence_threshold=None, hotwords=None), vad_options=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "571581ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s -> 7.00s]  שלום אני עוד את גפן ואני רוצה להציג את עצמי יש לי תואר ראשון בשני ושלישי\n"
     ]
    }
   ],
   "source": [
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6562f16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: he (confidence: 80.47%)\n"
     ]
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "\n",
    "# model = WhisperModel(\"base\", device=\"cuda\", compute_type=\"float32\")\n",
    "\n",
    "model = WhisperModel(\"base\", device=\"cpu\")\n",
    "\n",
    "# Just detect language (faster)\n",
    "audio_info = model.transcribe(r\"C:\\Users\\User\\OneDrive\\Documents\\Sound Recordings\\Recording (2).m4a\", beam_size=1, best_of=1)\n",
    "_, info = audio_info\n",
    "\n",
    "print(f\"Language: {info.language} (confidence: {info.language_probability:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f07b040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
